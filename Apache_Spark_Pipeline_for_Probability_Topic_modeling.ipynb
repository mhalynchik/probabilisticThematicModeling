{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "l8050x1cdiV2",
        "8dj1JJFKdfdX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "partitionNum = 240\n",
        "pocessSubset = True\n",
        "subsetCardinality = 10000 \n",
        "subsetPartitionNum = partitionNum // 120\n",
        "inputCol = \"abstract\"\n",
        "outputCol = \"probability vectors\"\n"
      ],
      "metadata": {
        "id": "baZlxacFmV2T"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download kaggle token and mount Google drive"
      ],
      "metadata": {
        "id": "FRsvN2SzMneV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qEcKaqyMteL",
        "outputId": "52e81beb-bf0d-45d6-a691-3267bbf01079"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        " \n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "AXq69LrcMotj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "518586c9-c382-4f2b-bb9c-64118f0aea07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f3414c38-396c-4c1d-86ce-e0ac71cdcf36\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f3414c38-396c-4c1d-86ce-e0ac71cdcf36\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "rm: cannot remove '/root/.kaggle': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install Dependencies"
      ],
      "metadata": {
        "id": "EbeOUNJxA5h8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NFLoRIwzQdSF"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyspark\n",
        "!pip install bigartm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import sys\n",
        "import os\n",
        "# installation of GOT (G eneralization O ver T axonomies) software package\n",
        "!mkdir gotlib\n",
        "if not os.listdir(\"gotlib\"):\n",
        "  !git clone https://github.com/dmitsf/GOT.git gotlib\n",
        "sys.path.append('gotlib')\n",
        "\n",
        "#library name spelled in caps in setup causes errors in Apache Spark\n",
        "!cp /content/drive/MyDrive/setup.py /content/gotlib/setup.py\n",
        "\n",
        "!cd gotlib && python setup.py install"
      ],
      "metadata": {
        "id": "_BnfMtyPKQj-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading taxonomies\n",
        "%%capture\n",
        "!cp /content/drive/MyDrive/arxiv_category_taxonomy.csv arxiv_category_taxonomy.csv \n",
        "\n",
        "!python3 /content/gotlib/got/taxonomies/taxonomy.py arxiv_category_taxonomy.csv "
      ],
      "metadata": {
        "id": "_glnH_UvNFsG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "with open(\"taxonomy_leaves.txt\") as f:\n",
        "    strings = [l.strip() for l in f.readlines()]\n",
        "\n",
        "taxanomy_leaves_df = pd.DataFrame.from_dict(dict(enumerate(strings)), orient='index', columns=[inputCol])"
      ],
      "metadata": {
        "id": "1xC1nIzlNjgh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install kaggle\n",
        "!kaggle datasets download -d Cornell-University/arxiv\n",
        "\n",
        "!mkdir Dataset\n",
        "!cp arxiv.zip Dataset/arxiv.zip\n",
        "!unzip -q Dataset/arxiv.zip -d Dataset\n",
        "!rm Dataset/arxiv.zip"
      ],
      "metadata": {
        "id": "IjR5X_BBDpAC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation of GOT libriary on Apache Spark"
      ],
      "metadata": {
        "id": "WodEY5cR7Qrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf\n",
        "from pyspark.context import SparkContext\n",
        "\n",
        "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
        "# add gotlib egg for Spark\n",
        "sc.addFile(path='/content/gotlib/dist/' + os.listdir('/content/gotlib/dist/')[0])"
      ],
      "metadata": {
        "id": "jp8feiLvWcFA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset schema"
      ],
      "metadata": {
        "id": "c3DakXFx7MyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "schema = StructType([\n",
        "StructField(\"id\",StringType(),True), \n",
        "StructField(\"submitter\",StringType(),True), \n",
        "StructField(\"authors\",StringType(),True),\n",
        "StructField(\"title\", StringType(), True),\n",
        "StructField(\"comments\", StringType(), True),\n",
        "StructField(\"journal-ref\", StringType(), True),\n",
        "StructField(\"doi\", StringType(), True),\n",
        "StructField(\"report-no\", StringType(), True),\n",
        "StructField(\"categories\", StringType(), True),\n",
        "StructField(\"abstract\", StringType(), True)])"
      ],
      "metadata": {
        "id": "4HUfxobV641H"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Dataset"
      ],
      "metadata": {
        "id": "e-soPMrX7XUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master('local').appName('Streaming Probability Topic Modeling Pipeline').config('spark.ui.port', '4050').getOrCreate()\n",
        "spark.conf.set('spark.rapids.sql.enabled','true/false')\n",
        "\n",
        "\n",
        "# Arxiv Dataset\n",
        "sentenceDataFrame = spark.read.json(\"/content/Dataset/arxiv-metadata-oai-snapshot.json\").repartition(partitionNum)\n",
        "if pocessSubset:\n",
        "  sentenceDataFrame = spark.createDataFrame(sentenceDataFrame.head(subsetCardinality), sentenceDataFrame.schema).repartition(subsetPartitionNum)\n",
        "\n",
        "# Taxonomy \n",
        "taxanomyDataFrame = spark.createDataFrame(taxanomy_leaves_df)"
      ],
      "metadata": {
        "id": "CIFxwxvdbiRW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Spark Pipeline Functions"
      ],
      "metadata": {
        "id": "ytWzktGcBULN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tokenizers"
      ],
      "metadata": {
        "id": "l8050x1cdiV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import keyword_only  ## < 2.0 -> pyspark.ml.util.keyword_only\n",
        "from pyspark.ml import Transformer\n",
        "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, HasPredictionCol, Param, Params, TypeConverters\n",
        "# Available in PySpark >= 2.3.0 \n",
        "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable  \n",
        "from pyspark.ml.pipeline import Estimator, Model, Pipeline\n",
        "from pyspark.ml.feature import CountVectorizer, StopWordsRemover, RegexTokenizer, CountVectorizerModel\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import artm\n",
        "from got.asts.ast import EASA\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "class ParGenMWordTokenizer(\n",
        "        Transformer, HasInputCol, HasOutputCol,\n",
        "        DefaultParamsReadable, DefaultParamsWritable):\n",
        "\n",
        "\n",
        "    @keyword_only\n",
        "    def __init__(self, inputCol=None, outputCol=None, lowerize=None):\n",
        "        super(ParGenMWordTokenizer, self).__init__()\n",
        "        self.lowerize =  Param(self, \"lowerize\", \"\")\n",
        "        kwargs = self._input_kwargs\n",
        "        self.setParams(**kwargs)\n",
        "\n",
        "    @keyword_only\n",
        "    def setParams(self, inputCol=None, outputCol=None, lowerize=None):\n",
        "        kwargs = self._input_kwargs\n",
        "        return self._set(**kwargs)\n",
        "\n",
        "    def getLowerize(self):\n",
        "        return self.getOrDefault(self.lowerize)\n",
        "\n",
        "    # Required in Spark >= 3.0\n",
        "    def setInputCol(self, value):\n",
        "        \"\"\"\n",
        "        Sets the value of :py:attr:`inputCol`.\n",
        "        \"\"\"\n",
        "        return self._set(inputCol=value)\n",
        "\n",
        "    # Required in Spark >= 3.0\n",
        "    def setOutputCol(self, value):\n",
        "        \"\"\"\n",
        "        Sets the value of :py:attr:`outputCol`.\n",
        "        \"\"\"\n",
        "        return self._set(outputCol=value)\n",
        "\n",
        "    def _transform(self, dataset):\n",
        "        def clear_text(text):\n",
        "          pat = re.compile(r'[^A-Za-z0-9 \\-\\n\\r.,;!?А-Яа-я]+')\n",
        "          cleared_text = re.sub(pat, ' ', text)\n",
        "\n",
        "          if self.getLowerize():\n",
        "              cleared_text = cleared_text.lower()\n",
        "\n",
        "          tokens = cleared_text.split()\n",
        "          return tokens\n",
        "\n",
        "        t = ArrayType(StringType())\n",
        "        out_col = self.getOutputCol()\n",
        "        in_col = dataset[self.getInputCol()]\n",
        "        return dataset.withColumn(out_col, udf(clear_text, t)(in_col))\n",
        "\n",
        "class StopWordsTokenizer(\n",
        "        Transformer, HasInputCol, HasOutputCol,\n",
        "        DefaultParamsReadable, DefaultParamsWritable):\n",
        "\n",
        "\n",
        "    @keyword_only\n",
        "    def __init__(self, inputCol=None, outputCol=None, stop_words=None):\n",
        "        super(StopWordsTokenizer, self).__init__()\n",
        "        self.stop_words = Param(self, \"stop_words\", \"\")\n",
        "        kwargs = self._input_kwargs\n",
        "        self.setParams(**kwargs)\n",
        "\n",
        "        self.reTokenizer = RegexTokenizer(pattern='[^A-Za-z\\-А-Яа-я]+', gaps=True, minTokenLength=3)\n",
        "        self.remover = StopWordsRemover(stopWords=stop_words)\n",
        "        self.cv = CountVectorizer(vocabSize=500000, minTF=3, minDF=5, maxDF=5e5)\n",
        "        self.trained = False\n",
        "\n",
        "\n",
        "        # Tokenizer: [\"User defined input column\"] -> [\"words\"]\n",
        "        self.reTokenizer.setOutputCol(\"words\")\n",
        "        \n",
        "        # Remover: [\"words\"] -> [\"tokens\"]\n",
        "        self.remover.setInputCol(\"words\")\n",
        "        self.remover.setOutputCol(\"tokens\")\n",
        "\n",
        "        # CountVectorizer: [\"tokens\"] -> [\"User defined output column\"]\n",
        "        self.cv.setInputCol(\"tokens\")\n",
        "  \n",
        "\n",
        "    @keyword_only\n",
        "    def setParams(self, inputCol=None, outputCol=None, stop_words=None):\n",
        "        kwargs = self._input_kwargs\n",
        "        return self._set(**kwargs)\n",
        "    \n",
        "    def getVocab(self):\n",
        "        return self.vocabulary\n",
        "\n",
        "    # Required in Spark >= 3.0\n",
        "    def setInputCol(self, value):\n",
        "        \"\"\"\n",
        "        Sets the value of :py:attr:`inputCol`.\n",
        "        \"\"\"\n",
        "        return self._set(inputCol=value)\n",
        "\n",
        "    # Required in Spark >= 3.0\n",
        "    def setOutputCol(self, value):\n",
        "        \"\"\"\n",
        "        Sets the value of :py:attr:`outputCol`.\n",
        "        \"\"\"\n",
        "        return self._set(outputCol=value)\n",
        "      \n",
        "    def setTrain(self):\n",
        "      return self._set(train=True)\n",
        "\n",
        "    def _tokenize(self, dataset):\n",
        "        self.reTokenizer.setInputCol(self.getInputCol())\n",
        "        dataset =  self.reTokenizer.transform(dataset)\n",
        "\n",
        "        dataset = self.remover.transform(dataset)\n",
        "        return dataset\n",
        "\n",
        "    def save(self, path):\n",
        "        self.modelcv.save(path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.modelcv = CountVectorizerModel.load(path)\n",
        "        self.vocabulary = self.modelcv.vocabulary\n",
        "        self.trained = True\n",
        "        \n",
        "\n",
        "    def fit(self, dataset):\n",
        "        dataset = self._tokenize(dataset)\n",
        "        self.cv.setOutputCol(self.getOutputCol())\n",
        "        self.modelcv = self.cv.fit(dataset)\n",
        "        self.vocabulary = self.modelcv.vocabulary\n",
        "        self.trained = True\n",
        "        return self\n",
        "\n",
        "    def _transform(self, dataset):\n",
        "        dataset = self._tokenize(dataset)\n",
        "\n",
        "        if not self.trained:\n",
        "          self.fit(dataset)\n",
        "        \n",
        "        dataset = self.modelcv.transform(dataset)\n",
        "        return dataset"
      ],
      "metadata": {
        "id": "uVD1bfNkQeXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5cab810-d9bf-4180-ef9a-b686efd8ddc6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/gotlib/got/asts/utils.py:33: DeprecationWarning: invalid escape sequence '\\w'\n",
            "  return re.findall(re.compile(\"[\\w']+\", re.U), text)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Estimators"
      ],
      "metadata": {
        "id": "8dj1JJFKdfdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.functions import vector_to_array\n",
        "from pyspark.sql.functions import array\n",
        "\n",
        "class ProbabilityMatrixEstimator(Estimator,\n",
        "        HasInputCol, HasPredictionCol,\n",
        "        DefaultParamsReadable, DefaultParamsWritable):\n",
        "\n",
        "    @keyword_only\n",
        "    def __init__(self, prepared_string_tokens, inputCol=None, predictionCol=None, \n",
        "                 modelType=\"AST\", vocabulary=None):\n",
        "        super(ProbabilityMatrixEstimator, self).__init__()\n",
        "        self.model = {\"AST\": ASTRelevanceMatrixModel,\n",
        "                      \"PLSA\": PLSAProbabilityMatrixModel,\n",
        "                      \"LDA\": LDAProbabilityMatrixModel,\n",
        "                      \"ARTM\": ARTMProbabilityMatrixModel}\n",
        "        self.modelType =  Param(self, \"modelType\", \"\")\n",
        "        self.prepared_string_tokens =  Param(self, \"prepared_string_tokens\", \"\")\n",
        "        self.vocabulary = Param(self, \"vocabulary\", \"\")\n",
        "        self.prepared_strings = None\n",
        "        kwargs = self._input_kwargs\n",
        "        self.setParams(**kwargs)\n",
        "        \n",
        "        if self.getOrDefault(self.modelType) not in self.model.keys():\n",
        "          raise Exception(\"Wrong model type\")\n",
        "\n",
        "        if self.getOrDefault(self.prepared_string_tokens) is not None:\n",
        "          self.prepared_strings = [' '.join(t) for t in self.getOrDefault(self.prepared_string_tokens)]\n",
        "        self.modelEstimator = None\n",
        "      \n",
        "\n",
        "\n",
        "    # Required in Spark >= 3.0\n",
        "    def setInputCol(self, value):\n",
        "        \"\"\"\n",
        "        Sets the value of :py:attr:`inputCol`.\n",
        "        \"\"\"\n",
        "        return self._set(inputCol=value)\n",
        "\n",
        "    # Required in Spark >= 3.0\n",
        "    def setPredictionCol(self, value):\n",
        "        \"\"\"\n",
        "        Sets the value of :py:attr:`predictionCol`.\n",
        "        \"\"\"\n",
        "        return self._set(predictionCol=value)\n",
        "\n",
        "    def setModelType(self, value):\n",
        "        \"\"\"\n",
        "        Sets the value of :py:attr:`modelType`.\n",
        "        \"\"\"\n",
        "        return self._set(modelType=value)\n",
        "    def getModelEstimator(self):\n",
        "        return self.modelEstimator\n",
        "\n",
        "\n",
        "    @keyword_only\n",
        "    def setParams(self, prepared_string_tokens, inputCol=None, predictionCol=None, modelType=\"AST\", vocabulary=None):\n",
        "        kwargs = self._input_kwargs\n",
        "        return self._set(**kwargs)        \n",
        "        \n",
        "    def _fit(self, dataset):\n",
        "      self.modelEstimator = self.model[self.getOrDefault(self.modelType)](\n",
        "            inputCol = self.getInputCol(),\n",
        "            prepared_strings = self.prepared_strings,\n",
        "            predictionCol = self.getPredictionCol(),\n",
        "            vocabulary=self.getOrDefault(self.vocabulary),\n",
        "            topics_num=15, tokens_num=20, iter_over_document=5, iter_over_collection=20)\n",
        "      return self.modelEstimator\n",
        "\n",
        "        \n",
        "class ProbabilityMatrixModel(Model, HasInputCol, HasPredictionCol,\n",
        "        DefaultParamsReadable, DefaultParamsWritable):\n",
        "\n",
        "    @keyword_only\n",
        "    def __init__(self, inputCol=None, predictionCol=None,\n",
        "                prepared_strings=None,\n",
        "                vocabulary=None,\n",
        "                topics_num=15, tokens_num=20, iter_over_document=5, iter_over_collection=20):\n",
        "        super(ProbabilityMatrixModel, self).__init__()\n",
        "        self.prepared_strings  =  Param(self, \"prepared_strings\", \"\")\n",
        "        self.vocabulary = Param(self, \"vocabulary\", \"\")\n",
        "\n",
        "        # artm models params(for retrain)\n",
        "        self.topics_num = Param(self, \"topics_num\", \"\")\n",
        "        self.tokens_num = Param(self, \"tokens_num\", \"\")\n",
        "        self.iter_over_document = Param(self, \"iter_over_document\", \"\")\n",
        "        self.iter_over_collection = Param(self, \"iter_over_collection\", \"\")\n",
        "        \n",
        "        kwargs = self._input_kwargs\n",
        "        self.setParams(**kwargs) \n",
        "        self.model = None\n",
        "        \n",
        "\n",
        "    @keyword_only\n",
        "    def setParams(self, inputCol=None, predictionCol=None,\n",
        "                prepared_strings=None,\n",
        "                vocabulary=None,\n",
        "                topics_num=15, tokens_num=20, iter_over_document=5, iter_over_collection=20):\n",
        "        kwargs = self._input_kwargs\n",
        "        return self._set(**kwargs)\n",
        "\n",
        "class ASTRelevanceMatrixModel(ProbabilityMatrixModel):\n",
        "    def _transform(self, dataset):\n",
        "        def make_substrings(tokens, k=4):\n",
        "          for i in range(max(len(tokens) - k + 1, 1)):\n",
        "              yield ' '.join(tokens[i:i + k])\n",
        "\n",
        "        def get_relevance_matrix(cleared_tokens):\n",
        "          ast = EASA(list(make_substrings(cleared_tokens)))\n",
        "          row = [float(ast.score(s)) for s in self.getOrDefault(self.prepared_strings)]\n",
        "          return row\n",
        "\n",
        "        t = ArrayType(DoubleType())\n",
        "        out_col = self.getPredictionCol()\n",
        "        in_col = dataset[self.getInputCol()]\n",
        "        return dataset.withColumn(out_col, udf(get_relevance_matrix, t)(in_col))\n",
        "    \n",
        "    def train(self, dataset):\n",
        "      return self\n",
        "\n",
        "\n",
        "class ARTMModel(ProbabilityMatrixModel):\n",
        "  def _transform(self, dataset):\n",
        "    n_wd = np.apply_along_axis(lambda x: x[0].toArray(), 1, dataset[[self.getInputCol()]].toPandas().to_numpy()).T\n",
        "    bv = artm.BatchVectorizer(data_format='bow_n_wd',\n",
        "                              n_wd=n_wd,\n",
        "                              vocabulary=self.getOrDefault(self.vocabulary))\n",
        "    if self.model is None:\n",
        "      print(\"the ARTM model is not pretrained, training on the transferred dataset\")\n",
        "      self.train(dataset)\n",
        "    res = self.model.transform(bv).T\n",
        "    res['id'] = dataset[['id']].toPandas()\n",
        "    res = spark.createDataFrame(res).select('id', array(['topic_' + str(i) for i in range(1, 15)]).alias(self.getInputCol()))\n",
        "    \n",
        "    return dataset.join(res, dataset.id == res.id, 'left')\n",
        "\n",
        "  def loadModel(self, path):\n",
        "    try:\n",
        "      self.model = artm.load_artm_model(path)\n",
        "    except:\n",
        "      raise Exception(\"Wrong model path or model type\")\n",
        "    return self\n",
        "\n",
        "  def saveModel(self, path):\n",
        "    self.model.dump_artm_model(path)\n",
        "\n",
        "\n",
        "class PLSAProbabilityMatrixModel(ARTMModel):\n",
        "  def train(self, dataset):\n",
        "    n_wd = np.apply_along_axis(lambda x: x[0].toArray(), 1, dataset[[self.getInputCol()]].toPandas().to_numpy()).T\n",
        "    bv = artm.BatchVectorizer(data_format='bow_n_wd',\n",
        "                              n_wd=n_wd,\n",
        "                              vocabulary=self.getOrDefault(self.vocabulary))\n",
        "    \n",
        "    self.model = artm.ARTM(num_topics=self.getOrDefault(self.topics_num), cache_theta=True,\n",
        "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
        "                                                    dictionary=bv.dictionary)])\n",
        "    self.model.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
        "    self.model.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
        "    self.model.scores.add(artm.TopicKernelScore(name='TopicKernelScore',\n",
        "                                                probability_mass_threshold=0.3))\n",
        "    self.model.scores.add(artm.TopTokensScore(name='TopTokensScore', \n",
        "                                              num_tokens=self.getOrDefault(self.topics_num)))\n",
        "    self.model.num_document_passes = self.getOrDefault(self.iter_over_document)\n",
        "    \n",
        "    \n",
        "    self.model.initialize(bv.dictionary)\n",
        "    self.model.fit_offline(batch_vectorizer=bv, \n",
        "                           num_collection_passes=self.getOrDefault(self.iter_over_collection))\n",
        "    return self\n",
        "    \n",
        "\n",
        "class LDAProbabilityMatrixModel(ARTMModel):\n",
        "  def train(self, dataset):\n",
        "    n_wd = np.apply_along_axis(lambda x: x[0].toArray(), 1, dataset[[self.getInputCol()]].toPandas().to_numpy()).T\n",
        "    bv = artm.BatchVectorizer(data_format='bow_n_wd',\n",
        "                              n_wd=n_wd,\n",
        "                              vocabulary=self.getOrDefault(self.vocabulary))\n",
        "\n",
        "    self.model = artm.LDA(num_topics=self.getOrDefault(self.topics_num), cache_theta=True)\n",
        "    self.model.num_document_passes = self.getOrDefault(self.iter_over_document)\n",
        "    \n",
        "    \n",
        "    self.model.initialize(bv.dictionary)\n",
        "    self.model.fit_offline(batch_vectorizer=bv, \n",
        "                          num_collection_passes=self.getOrDefault(self.iter_over_collection))\n",
        "    return self\n",
        "\n",
        "class ARTMProbabilityMatrixModel(ARTMModel):\n",
        "  def train(self, dataset):\n",
        "    n_wd = np.apply_along_axis(lambda x: x[0].toArray(), 1, dataset[[self.getInputCol()]].toPandas().to_numpy()).T\n",
        "    bv = artm.BatchVectorizer(data_format='bow_n_wd',\n",
        "                              n_wd=n_wd,\n",
        "                              vocabulary=self.getOrDefault(self.vocabulary))\n",
        "\n",
        "    self.model = artm.ARTM(num_topics=self.getOrDefault(self.topics_num), cache_theta=True,\n",
        "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
        "                                                    dictionary=bv.dictionary)],\n",
        "                       regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta',\n",
        "                                                                       tau=-0.15)])\n",
        "    self.model.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
        "    self.model.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
        "    self.model.scores.add(artm.TopicKernelScore(name='TopicKernelScore',\n",
        "                                                      probability_mass_threshold=0.3))\n",
        "    self.model.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=self.getOrDefault(self.tokens_num)))\n",
        "\n",
        "    self.model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1))\n",
        "    self.model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=1.5e+5))\n",
        "\n",
        "    self.model.num_document_passes = self.getOrDefault(self.iter_over_document)\n",
        "\n",
        "    \n",
        "    self.model.initialize(bv.dictionary)\n",
        "    self.model.fit_offline(batch_vectorizer=bv, num_collection_passes=self.getOrDefault(self.iter_over_collection))\n",
        "    return self\n"
      ],
      "metadata": {
        "id": "rvAGUfgmdeO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e04fa91-f4eb-4f49-b1e8-c39d0a70474d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pipeline"
      ],
      "metadata": {
        "id": "Zh0rhNueBaZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
      ],
      "metadata": {
        "id": "JIPUl_ZgpiW0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get batch vectorizer for ARTM"
      ],
      "metadata": {
        "id": "CUNs-2ZFbq-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['allow', 'almost', 'also', 'approach', 'asume', 'bad', 'behavior',\n",
        "                  'consider', 'constant', 'control', 'datum', 'density', 'describe',\n",
        "                  'description', 'direction', 'discuss', 'edu', 'effect',\n",
        "                  'effective', 'energy', 'example', 'experimental', 'field', 'find',\n",
        "                  'fine', 'first', 'form', 'from', 'give', 'high', 'investigate',\n",
        "                  'know', 'known', 'large', 'lead', 'let', 'long', 'low', 'make', 'model',\n",
        "                  'new', 'non', 'observe', 'obtain', 'paper', 'parameter',\n",
        "                  'particular', 'point', 'positive', 'present', 'problem',\n",
        "                  'property', 'propose', 'result', 'sample', 'search', 'show',\n",
        "                  'small', 'state', 'study', 'subject', 'suggest', 'suppose',\n",
        "                  'system', 'theory', 'time', 'use', 'well', 'word', 'work', ' ', ''])\n",
        "\n",
        "\n",
        "tokenizerParGenM = ParGenMWordTokenizer(\n",
        "    inputCol=inputCol, outputCol=\"tokens\",  \n",
        "    lowerize=True)\n",
        "\n",
        "# Tokenize Taxonomy\n",
        "taxanomyDataFrame = tokenizerParGenM.transform(taxanomyDataFrame)\n",
        "string_tokens = taxanomyDataFrame.toPandas().tokens\n"
      ],
      "metadata": {
        "id": "H0oi0PM3QrCl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizerARTM = StopWordsTokenizer(\n",
        "    inputCol=\"abstract\", outputCol=\"vectors\", \n",
        "    stop_words=stop_words).fit(sentenceDataFrame)\n",
        "dataset = tokenizerARTM.transform(sentenceDataFrame)\n",
        "estimator = ProbabilityMatrixEstimator(inputCol=\"vectors\", \n",
        "                                        predictionCol=outputCol, \n",
        "                                        modelType=\"PLSA\",\n",
        "                                        prepared_string_tokens=string_tokens,\n",
        "                                        vocabulary=tokenizerARTM.getVocab())"
      ],
      "metadata": {
        "id": "glaIyJ7_aFze"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline(stages=[tokenizerARTM, estimator])\n",
        "res = model.fit(sentenceDataFrame).transform(sentenceDataFrame)\n",
        "res.show()"
      ],
      "metadata": {
        "id": "USOttyIYDg3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c226559e-5d1c-4834-8783-c6d1c0c5b740"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the ARTM model is not pretrained, training on the transferred dataset\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "|            abstract|             authors|      authors_parsed|          categories|            comments|                 doi|        id|         journal-ref|             license|report-no|           submitter|               title|update_date|            versions|               words|              tokens|             vectors|        id|             vectors|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "|  The peak amplit...|      Sujan Sengupta|[[Sengupta, Sujan...|            astro-ph|16 pages includin...|      10.1086/591733| 0807.1794|                null|http://arxiv.org/...|     null|      Sujan Sengupta|Cloudy Atmosphere...| 2009-11-13|[{Fri, 11 Jul 200...|[the, peak, ampli...|[peak, amplitude,...|(9964,[431,1120],...| 0807.1794|[0.0, 0.0, 0.0, 0...|\n",
            "|  The antiferroma...|   Carlos P. Herrero|[[Herrero, Carlos...|     cond-mat.dis-nn|  7 pages, 6 figures|10.1140/epjb/e200...| 0908.3560|Eur. Phys. J. B 7...|http://arxiv.org/...|     null|   Carlos P. Herrero|Antiferromagnetic...| 2009-08-26|[{Tue, 25 Aug 200...|[the, antiferroma...|[antiferromagneti...|(9964,[70,126,342...| 0908.3560|[0.0, 1.068077629...|\n",
            "|  Models and meth...|Benjamin Collyer,...|[[Collyer, Benjam...|     physics.comp-ph|                null|10.1016/j.jcp.201...|1509.01015|                null|http://arxiv.org/...|     null|         Ben Collyer|Importance Sampli...| 2016-09-21|[{Thu, 3 Sep 2015...|[models, and, met...|[models, methods,...|(9964,[7,196,347,...|1509.01015|[0.0, 0.0, 0.2036...|\n",
            "|  An analytical m...|Mikhail B. Babenk...|[[Babenkov, Mikha...|cond-mat.stat-mec...|                null|                null|1802.02037|                null|http://arxiv.org/...|     null|    Mikhail Babenkov|Unsteady heat con...| 2018-02-07|[{Fri, 22 Dec 201...|[analytical, mode...|[analytical, freq...|   (9964,[49],[3.0])|1802.02037|[0.0, 0.0, 8.3333...|\n",
            "|  Recently, compr...|Sankalp Pawar, Se...|[[Pawar, Sankalp,...|             eess.SP|                null|                null|1811.01554|                null|http://arxiv.org/...|     null|    Sebastian Semper|Combining Matrix ...| 2018-11-06|[{Mon, 5 Nov 2018...|[recently, compre...|[recently, compre...|(9964,[1194,1944,...|1811.01554|[0.06666667014360...|\n",
            "|  We show that th...|Todd A. Thompson ...|[[Thompson, Todd ...|         astro-ph.GA|  9 pages, 5 figures|10.1093/mnras/stv...| 1411.1769|MNRAS 455, 334-34...|http://arxiv.org/...|     null|    Todd A. Thompson|Sub-Eddington Sta...| 2015-12-16|[{Thu, 6 Nov 2014...|[show, that, the,...|[turbulent, gas, ...|(9964,[15,63,101,...| 1411.1769|[3.91346830497241...|\n",
            "|  From some works...|Georges Gras, Rol...|[[Gras, Georges, ...|             math.NT|This second versi...|                null| 1103.4692|                null|http://arxiv.org/...|     null|        Georges Gras|Some works of Fur...| 2011-04-14|[{Thu, 24 Mar 201...|[from, some, work...|[works, furtw, an...|(9964,[257,4125,4...| 1103.4692|[0.0, 0.0, 0.0, 0...|\n",
            "|  The stability o...|        Ahmad Borzou| [[Borzou, Ahmad, ]]|astro-ph.CO astro...|15 pages, 14 figu...|10.1140/epjc/s100...|2003.04532|Eur. Phys. J. C 8...|http://arxiv.org/...|     null|        Ahmad Borzou|On the Stability ...| 2020-11-24|[{Tue, 10 Mar 202...|[the, stability, ...|[stability, isoth...|(9964,[15,40,87,2...|2003.04532|[0.49999997019767...|\n",
            "|  In this paper w...| Riccardo Cristoferi|[[Cristoferi, Ric...|             math.OC|23 pages, 14 figures|                null|1612.05508|                null|http://arxiv.org/...|     null| Riccardo Cristoferi|Exact solutions f...| 2017-09-12|[{Fri, 16 Dec 201...|[this, paper, pro...|[method, determin...|        (9964,[],[])|1612.05508|[0.06666667014360...|\n",
            "|  Let $w$ be a se...|Gordon Blower and...|[[Blower, Gordon,...|     math.FA math.CA|            30 pages|                null|1901.05788|                null|http://arxiv.org/...|     null|       Gordon Blower|On determinant ex...| 2019-02-07|[{Thu, 17 Jan 201...|[let, semiclassic...|[semiclassical, w...|(9964,[126,631,10...|1901.05788|[0.23076926171779...|\n",
            "|  We present an o...|Yongxin Chen, Try...|[[Chen, Yongxin, ...|       math.PR cs.SY|14 pages, 10 figures|                null|1710.07876|                null|http://arxiv.org/...|     null|        Yongxin Chen|Optimal transport...| 2018-02-01|[{Sun, 22 Oct 201...|[present, optimal...|[optimal, mass, t...|    (9964,[5],[3.0])|1710.07876|[0.0, 0.0, 1.0, 0...|\n",
            "|  Hysteresis oper...|Christian Kuehn a...|[[Kuehn, Christia...|math.DS math.CA n...|36 pages, 9 figur...|  10.1137/17M1110584|1701.00229|SIAM Journal on A...|http://arxiv.org/...|     null|     Christian Kuehn|Generalized Play ...| 2018-12-24|[{Sun, 1 Jan 2017...|[hysteresis, oper...|[hysteresis, oper...|(9964,[10,78,256,...|1701.00229|[0.11999243497848...|\n",
            "|  Predicate encry...|         Kwangsu Lee|  [[Lee, Kwangsu, ]]|               cs.CR|PhD Thesis, Korea...|                null|1702.07456|                null|http://arxiv.org/...|     null|         Kwangsu Lee|Efficient Hidden ...| 2017-02-27|[{Fri, 24 Feb 201...|[predicate, encry...|[predicate, encry...|(9964,[0,2,14,184...|1702.07456|[0.0, 0.0, 0.0, 0...|\n",
            "|  In recent work ...|J.I.A. Li, A.M. Z...|[[Li, J. I. A., ]...|   cond-mat.supr-con|4 pages and 3 fig...|10.1103/PhysRevLe...| 1401.5153|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|            J.I.A Li|Stability of supe...| 2014-03-19|[{Tue, 21 Jan 201...|[recent, work, wa...|[recent, shown, a...| (9964,[1577],[3.0])| 1401.5153|[0.0, 0.0, 0.5000...|\n",
            "|  Given a commuta...|         Liran Shaul|  [[Shaul, Liran, ]]|     math.AC math.AG|10 pages, final v...|10.1016/j.jpaa.20...|2002.05055|Journal of Pure a...|http://arxiv.org/...|     null|         Liran Shaul|Open loci results...| 2021-10-25|[{Wed, 12 Feb 202...|[given, commutati...|[given, commutati...|(9964,[316,3624,4...|2002.05055|[0.0, 0.0, 0.2533...|\n",
            "|  Related to a se...|Frederic Bernicot...|[[Bernicot, Frede...|             math.CA|            20 pages|                null| 1212.2349|                null|http://arxiv.org/...|     null|   Frederic Bernicot|Pseudodifferentia...| 2012-12-12|[{Tue, 11 Dec 201...|[related, semigro...|[related, semigro...|  (9964,[256],[3.0])| 1212.2349|[0.0, 0.0, 0.0, 0...|\n",
            "|  In an uncoordin...|Alphan Sahin, Erd...|[[Sahin, Alphan, ...|       cs.IT math.IT|Submitted to IEEE...|10.1109/TCOMM.201...| 1312.3662|                null|http://arxiv.org/...|     null|Alphan Sahin Alph...|Partially Overlap...| 2016-11-17|[{Thu, 12 Dec 201...|[uncoordinated, n...|[uncoordinated, n...|  (9964,[985],[4.0])| 1312.3662|[0.06666667014360...|\n",
            "|  This is era of ...|Rafiullah Khan an...|[[Khan, Rafiullah...|               cs.NI|  8 Pages, 4 figures|10.5121/cseij.201...| 1305.2708|                null|http://creativeco...|     null|      Rafiullah Khan|Conceptual Framew...| 2013-05-14|[{Mon, 13 May 201...|[this, era, infor...|[era, information...|(9964,[29,903,109...| 1305.2708|[0.0, 0.0, 0.0, 0...|\n",
            "|  The three-dimen...|Markus J. Aschwan...|[[Aschwanden, Mar...|         astro-ph.SR|The Astrophysical...|10.1088/0004-637X...| 1207.2790|                null|http://arxiv.org/...|     null|   Markus Aschwanden|First 3D Reconstr...| 2015-06-05|[{Wed, 11 Jul 201...|[the, three-dimen...|[three-dimensiona...|(9964,[20,106,283...| 1207.2790|[0.0, 2.402885182...|\n",
            "|  Despite being a...|J. A. Sherman, N....|[[Sherman, J. A.,...|physics.atom-ph p...|5 pages, 3 figure...|10.1103/PhysRevLe...| 1112.2766|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|        Jeff Sherman|High accuracy mea...| 2012-04-18|[{Tue, 13 Dec 201...|[despite, being, ...|[despite, canonic...|(9964,[93,411,351...| 1112.2766|[0.0, 0.0, 0.0, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizerARTM.save(\"count-vectorizer\")\n",
        "model.getStages()[1].getModelEstimator().saveModel(\"plsa_model\")"
      ],
      "metadata": {
        "id": "G_lxzvbf3vqg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator2 = ProbabilityMatrixEstimator(inputCol=\"vectors\", \n",
        "                                        predictionCol=outputCol, \n",
        "                                        modelType=\"PLSA\",\n",
        "                                        prepared_string_tokens=string_tokens,\n",
        "                                        vocabulary=tokenizerARTM.getVocab()).fit(dataset) # fit only for getting probability model class, no need to specify correct dataFrame\n",
        "\n",
        "estimator2.loadModel(\"plsa_model\").transform(dataset).show()"
      ],
      "metadata": {
        "id": "dTJ9gu8AUmAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85478e68-9d95-4a0f-a2db-bb2ba5abcd69"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "|            abstract|             authors|      authors_parsed|          categories|            comments|                 doi|        id|         journal-ref|             license|report-no|           submitter|               title|update_date|            versions|               words|              tokens|             vectors|        id|             vectors|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "|  The peak amplit...|      Sujan Sengupta|[[Sengupta, Sujan...|            astro-ph|16 pages includin...|      10.1086/591733| 0807.1794|                null|http://arxiv.org/...|     null|      Sujan Sengupta|Cloudy Atmosphere...| 2009-11-13|[{Fri, 11 Jul 200...|[the, peak, ampli...|[peak, amplitude,...|(9964,[431,1120],...| 0807.1794|[0.0, 0.0, 0.0, 0...|\n",
            "|  The antiferroma...|   Carlos P. Herrero|[[Herrero, Carlos...|     cond-mat.dis-nn|  7 pages, 6 figures|10.1140/epjb/e200...| 0908.3560|Eur. Phys. J. B 7...|http://arxiv.org/...|     null|   Carlos P. Herrero|Antiferromagnetic...| 2009-08-26|[{Tue, 25 Aug 200...|[the, antiferroma...|[antiferromagneti...|(9964,[70,126,342...| 0908.3560|[0.0, 1.068077629...|\n",
            "|  Models and meth...|Benjamin Collyer,...|[[Collyer, Benjam...|     physics.comp-ph|                null|10.1016/j.jcp.201...|1509.01015|                null|http://arxiv.org/...|     null|         Ben Collyer|Importance Sampli...| 2016-09-21|[{Thu, 3 Sep 2015...|[models, and, met...|[models, methods,...|(9964,[7,196,347,...|1509.01015|[0.0, 0.0, 0.2036...|\n",
            "|  An analytical m...|Mikhail B. Babenk...|[[Babenkov, Mikha...|cond-mat.stat-mec...|                null|                null|1802.02037|                null|http://arxiv.org/...|     null|    Mikhail Babenkov|Unsteady heat con...| 2018-02-07|[{Fri, 22 Dec 201...|[analytical, mode...|[analytical, freq...|   (9964,[49],[3.0])|1802.02037|[0.0, 0.0, 8.3333...|\n",
            "|  Recently, compr...|Sankalp Pawar, Se...|[[Pawar, Sankalp,...|             eess.SP|                null|                null|1811.01554|                null|http://arxiv.org/...|     null|    Sebastian Semper|Combining Matrix ...| 2018-11-06|[{Mon, 5 Nov 2018...|[recently, compre...|[recently, compre...|(9964,[1194,1944,...|1811.01554|[0.06666667014360...|\n",
            "|  We show that th...|Todd A. Thompson ...|[[Thompson, Todd ...|         astro-ph.GA|  9 pages, 5 figures|10.1093/mnras/stv...| 1411.1769|MNRAS 455, 334-34...|http://arxiv.org/...|     null|    Todd A. Thompson|Sub-Eddington Sta...| 2015-12-16|[{Thu, 6 Nov 2014...|[show, that, the,...|[turbulent, gas, ...|(9964,[15,63,101,...| 1411.1769|[3.91346830497241...|\n",
            "|  From some works...|Georges Gras, Rol...|[[Gras, Georges, ...|             math.NT|This second versi...|                null| 1103.4692|                null|http://arxiv.org/...|     null|        Georges Gras|Some works of Fur...| 2011-04-14|[{Thu, 24 Mar 201...|[from, some, work...|[works, furtw, an...|(9964,[257,4125,4...| 1103.4692|[0.0, 0.0, 0.0, 0...|\n",
            "|  The stability o...|        Ahmad Borzou| [[Borzou, Ahmad, ]]|astro-ph.CO astro...|15 pages, 14 figu...|10.1140/epjc/s100...|2003.04532|Eur. Phys. J. C 8...|http://arxiv.org/...|     null|        Ahmad Borzou|On the Stability ...| 2020-11-24|[{Tue, 10 Mar 202...|[the, stability, ...|[stability, isoth...|(9964,[15,40,87,2...|2003.04532|[0.49999997019767...|\n",
            "|  In this paper w...| Riccardo Cristoferi|[[Cristoferi, Ric...|             math.OC|23 pages, 14 figures|                null|1612.05508|                null|http://arxiv.org/...|     null| Riccardo Cristoferi|Exact solutions f...| 2017-09-12|[{Fri, 16 Dec 201...|[this, paper, pro...|[method, determin...|        (9964,[],[])|1612.05508|[0.06666667014360...|\n",
            "|  Let $w$ be a se...|Gordon Blower and...|[[Blower, Gordon,...|     math.FA math.CA|            30 pages|                null|1901.05788|                null|http://arxiv.org/...|     null|       Gordon Blower|On determinant ex...| 2019-02-07|[{Thu, 17 Jan 201...|[let, semiclassic...|[semiclassical, w...|(9964,[126,631,10...|1901.05788|[0.23076926171779...|\n",
            "|  We present an o...|Yongxin Chen, Try...|[[Chen, Yongxin, ...|       math.PR cs.SY|14 pages, 10 figures|                null|1710.07876|                null|http://arxiv.org/...|     null|        Yongxin Chen|Optimal transport...| 2018-02-01|[{Sun, 22 Oct 201...|[present, optimal...|[optimal, mass, t...|    (9964,[5],[3.0])|1710.07876|[0.0, 0.0, 1.0, 0...|\n",
            "|  Hysteresis oper...|Christian Kuehn a...|[[Kuehn, Christia...|math.DS math.CA n...|36 pages, 9 figur...|  10.1137/17M1110584|1701.00229|SIAM Journal on A...|http://arxiv.org/...|     null|     Christian Kuehn|Generalized Play ...| 2018-12-24|[{Sun, 1 Jan 2017...|[hysteresis, oper...|[hysteresis, oper...|(9964,[10,78,256,...|1701.00229|[0.11999243497848...|\n",
            "|  Predicate encry...|         Kwangsu Lee|  [[Lee, Kwangsu, ]]|               cs.CR|PhD Thesis, Korea...|                null|1702.07456|                null|http://arxiv.org/...|     null|         Kwangsu Lee|Efficient Hidden ...| 2017-02-27|[{Fri, 24 Feb 201...|[predicate, encry...|[predicate, encry...|(9964,[0,2,14,184...|1702.07456|[0.0, 0.0, 0.0, 0...|\n",
            "|  In recent work ...|J.I.A. Li, A.M. Z...|[[Li, J. I. A., ]...|   cond-mat.supr-con|4 pages and 3 fig...|10.1103/PhysRevLe...| 1401.5153|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|            J.I.A Li|Stability of supe...| 2014-03-19|[{Tue, 21 Jan 201...|[recent, work, wa...|[recent, shown, a...| (9964,[1577],[3.0])| 1401.5153|[0.0, 0.0, 0.5000...|\n",
            "|  Given a commuta...|         Liran Shaul|  [[Shaul, Liran, ]]|     math.AC math.AG|10 pages, final v...|10.1016/j.jpaa.20...|2002.05055|Journal of Pure a...|http://arxiv.org/...|     null|         Liran Shaul|Open loci results...| 2021-10-25|[{Wed, 12 Feb 202...|[given, commutati...|[given, commutati...|(9964,[316,3624,4...|2002.05055|[0.0, 0.0, 0.2533...|\n",
            "|  Related to a se...|Frederic Bernicot...|[[Bernicot, Frede...|             math.CA|            20 pages|                null| 1212.2349|                null|http://arxiv.org/...|     null|   Frederic Bernicot|Pseudodifferentia...| 2012-12-12|[{Tue, 11 Dec 201...|[related, semigro...|[related, semigro...|  (9964,[256],[3.0])| 1212.2349|[0.0, 0.0, 0.0, 0...|\n",
            "|  In an uncoordin...|Alphan Sahin, Erd...|[[Sahin, Alphan, ...|       cs.IT math.IT|Submitted to IEEE...|10.1109/TCOMM.201...| 1312.3662|                null|http://arxiv.org/...|     null|Alphan Sahin Alph...|Partially Overlap...| 2016-11-17|[{Thu, 12 Dec 201...|[uncoordinated, n...|[uncoordinated, n...|  (9964,[985],[4.0])| 1312.3662|[0.06666667014360...|\n",
            "|  This is era of ...|Rafiullah Khan an...|[[Khan, Rafiullah...|               cs.NI|  8 Pages, 4 figures|10.5121/cseij.201...| 1305.2708|                null|http://creativeco...|     null|      Rafiullah Khan|Conceptual Framew...| 2013-05-14|[{Mon, 13 May 201...|[this, era, infor...|[era, information...|(9964,[29,903,109...| 1305.2708|[0.0, 0.0, 0.0, 0...|\n",
            "|  The three-dimen...|Markus J. Aschwan...|[[Aschwanden, Mar...|         astro-ph.SR|The Astrophysical...|10.1088/0004-637X...| 1207.2790|                null|http://arxiv.org/...|     null|   Markus Aschwanden|First 3D Reconstr...| 2015-06-05|[{Wed, 11 Jul 201...|[the, three-dimen...|[three-dimensiona...|(9964,[20,106,283...| 1207.2790|[0.0, 2.402885182...|\n",
            "|  Despite being a...|J. A. Sherman, N....|[[Sherman, J. A.,...|physics.atom-ph p...|5 pages, 3 figure...|10.1103/PhysRevLe...| 1112.2766|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|        Jeff Sherman|High accuracy mea...| 2012-04-18|[{Tue, 13 Dec 201...|[despite, being, ...|[despite, canonic...|(9964,[93,411,351...| 1112.2766|[0.0, 0.0, 0.0, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator.setModelType(\"LDA\")\n",
        "model = Pipeline(stages=[tokenizerARTM , estimator])\n",
        "res = model.fit(sentenceDataFrame).transform(sentenceDataFrame)\n",
        "res.show()"
      ],
      "metadata": {
        "id": "lrulrmIeI7ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80956104-2705-4abc-a8fe-af70421ed329"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the ARTM model is not pretrained, training on the transferred dataset\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "|            abstract|             authors|      authors_parsed|          categories|            comments|                 doi|        id|         journal-ref|             license|report-no|           submitter|               title|update_date|            versions|               words|              tokens|             vectors|        id|             vectors|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "|  The peak amplit...|      Sujan Sengupta|[[Sengupta, Sujan...|            astro-ph|16 pages includin...|      10.1086/591733| 0807.1794|                null|http://arxiv.org/...|     null|      Sujan Sengupta|Cloudy Atmosphere...| 2009-11-13|[{Fri, 11 Jul 200...|[the, peak, ampli...|[peak, amplitude,...|(9964,[431,1120],...| 0807.1794|[5.51328703295439...|\n",
            "|  The antiferroma...|   Carlos P. Herrero|[[Herrero, Carlos...|     cond-mat.dis-nn|  7 pages, 6 figures|10.1140/epjb/e200...| 0908.3560|Eur. Phys. J. B 7...|http://arxiv.org/...|     null|   Carlos P. Herrero|Antiferromagnetic...| 2009-08-26|[{Tue, 25 Aug 200...|[the, antiferroma...|[antiferromagneti...|(9964,[70,126,342...| 0908.3560|[3.21853498462587...|\n",
            "|  Models and meth...|Benjamin Collyer,...|[[Collyer, Benjam...|     physics.comp-ph|                null|10.1016/j.jcp.201...|1509.01015|                null|http://arxiv.org/...|     null|         Ben Collyer|Importance Sampli...| 2016-09-21|[{Thu, 3 Sep 2015...|[models, and, met...|[models, methods,...|(9964,[7,196,347,...|1509.01015|[1.84794393135234...|\n",
            "|  An analytical m...|Mikhail B. Babenk...|[[Babenkov, Mikha...|cond-mat.stat-mec...|                null|                null|1802.02037|                null|http://arxiv.org/...|     null|    Mikhail Babenkov|Unsteady heat con...| 2018-02-07|[{Fri, 22 Dec 201...|[analytical, mode...|[analytical, freq...|   (9964,[49],[3.0])|1802.02037|[8.23680020403116...|\n",
            "|  Recently, compr...|Sankalp Pawar, Se...|[[Pawar, Sankalp,...|             eess.SP|                null|                null|1811.01554|                null|http://arxiv.org/...|     null|    Sebastian Semper|Combining Matrix ...| 2018-11-06|[{Mon, 5 Nov 2018...|[recently, compre...|[recently, compre...|(9964,[1194,1944,...|1811.01554|[0.06666667014360...|\n",
            "|  We show that th...|Todd A. Thompson ...|[[Thompson, Todd ...|         astro-ph.GA|  9 pages, 5 figures|10.1093/mnras/stv...| 1411.1769|MNRAS 455, 334-34...|http://arxiv.org/...|     null|    Todd A. Thompson|Sub-Eddington Sta...| 2015-12-16|[{Thu, 6 Nov 2014...|[show, that, the,...|[turbulent, gas, ...|(9964,[15,63,101,...| 1411.1769|[0.20317591726779...|\n",
            "|  From some works...|Georges Gras, Rol...|[[Gras, Georges, ...|             math.NT|This second versi...|                null| 1103.4692|                null|http://arxiv.org/...|     null|        Georges Gras|Some works of Fur...| 2011-04-14|[{Thu, 24 Mar 201...|[from, some, work...|[works, furtw, an...|(9964,[257,4125,4...| 1103.4692|[4.41572658019140...|\n",
            "|  The stability o...|        Ahmad Borzou| [[Borzou, Ahmad, ]]|astro-ph.CO astro...|15 pages, 14 figu...|10.1140/epjc/s100...|2003.04532|Eur. Phys. J. C 8...|http://arxiv.org/...|     null|        Ahmad Borzou|On the Stability ...| 2020-11-24|[{Tue, 10 Mar 202...|[the, stability, ...|[stability, isoth...|(9964,[15,40,87,2...|2003.04532|[0.48882809281349...|\n",
            "|  In this paper w...| Riccardo Cristoferi|[[Cristoferi, Ric...|             math.OC|23 pages, 14 figures|                null|1612.05508|                null|http://arxiv.org/...|     null| Riccardo Cristoferi|Exact solutions f...| 2017-09-12|[{Fri, 16 Dec 201...|[this, paper, pro...|[method, determin...|        (9964,[],[])|1612.05508|[0.06666667014360...|\n",
            "|  Let $w$ be a se...|Gordon Blower and...|[[Blower, Gordon,...|     math.FA math.CA|            30 pages|                null|1901.05788|                null|http://arxiv.org/...|     null|       Gordon Blower|On determinant ex...| 2019-02-07|[{Thu, 17 Jan 201...|[let, semiclassic...|[semiclassical, w...|(9964,[126,631,10...|1901.05788|[0.23030737042427...|\n",
            "|  We present an o...|Yongxin Chen, Try...|[[Chen, Yongxin, ...|       math.PR cs.SY|14 pages, 10 figures|                null|1710.07876|                null|http://arxiv.org/...|     null|        Yongxin Chen|Optimal transport...| 2018-02-01|[{Sun, 22 Oct 201...|[present, optimal...|[optimal, mass, t...|    (9964,[5],[3.0])|1710.07876|[0.00317556015215...|\n",
            "|  Hysteresis oper...|Christian Kuehn a...|[[Kuehn, Christia...|math.DS math.CA n...|36 pages, 9 figur...|  10.1137/17M1110584|1701.00229|SIAM Journal on A...|http://arxiv.org/...|     null|     Christian Kuehn|Generalized Play ...| 2018-12-24|[{Sun, 1 Jan 2017...|[hysteresis, oper...|[hysteresis, oper...|(9964,[10,78,256,...|1701.00229|[0.11392243951559...|\n",
            "|  Predicate encry...|         Kwangsu Lee|  [[Lee, Kwangsu, ]]|               cs.CR|PhD Thesis, Korea...|                null|1702.07456|                null|http://arxiv.org/...|     null|         Kwangsu Lee|Efficient Hidden ...| 2017-02-27|[{Fri, 24 Feb 201...|[predicate, encry...|[predicate, encry...|(9964,[0,2,14,184...|1702.07456|[0.00317980512045...|\n",
            "|  In recent work ...|J.I.A. Li, A.M. Z...|[[Li, J. I. A., ]...|   cond-mat.supr-con|4 pages and 3 fig...|10.1103/PhysRevLe...| 1401.5153|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|            J.I.A Li|Stability of supe...| 2014-03-19|[{Tue, 21 Jan 201...|[recent, work, wa...|[recent, shown, a...| (9964,[1577],[3.0])| 1401.5153|[0.00122756988275...|\n",
            "|  Given a commuta...|         Liran Shaul|  [[Shaul, Liran, ]]|     math.AC math.AG|10 pages, final v...|10.1016/j.jpaa.20...|2002.05055|Journal of Pure a...|http://arxiv.org/...|     null|         Liran Shaul|Open loci results...| 2021-10-25|[{Wed, 12 Feb 202...|[given, commutati...|[given, commutati...|(9964,[316,3624,4...|2002.05055|[3.03018488921225...|\n",
            "|  Related to a se...|Frederic Bernicot...|[[Bernicot, Frede...|             math.CA|            20 pages|                null| 1212.2349|                null|http://arxiv.org/...|     null|   Frederic Bernicot|Pseudodifferentia...| 2012-12-12|[{Tue, 11 Dec 201...|[related, semigro...|[related, semigro...|  (9964,[256],[3.0])| 1212.2349|[0.00317506957799...|\n",
            "|  In an uncoordin...|Alphan Sahin, Erd...|[[Sahin, Alphan, ...|       cs.IT math.IT|Submitted to IEEE...|10.1109/TCOMM.201...| 1312.3662|                null|http://arxiv.org/...|     null|Alphan Sahin Alph...|Partially Overlap...| 2016-11-17|[{Thu, 12 Dec 201...|[uncoordinated, n...|[uncoordinated, n...|  (9964,[985],[4.0])| 1312.3662|[0.06666667014360...|\n",
            "|  This is era of ...|Rafiullah Khan an...|[[Khan, Rafiullah...|               cs.NI|  8 Pages, 4 figures|10.5121/cseij.201...| 1305.2708|                null|http://creativeco...|     null|      Rafiullah Khan|Conceptual Framew...| 2013-05-14|[{Mon, 13 May 201...|[this, era, infor...|[era, information...|(9964,[29,903,109...| 1305.2708|[0.00194185273721...|\n",
            "|  The three-dimen...|Markus J. Aschwan...|[[Aschwanden, Mar...|         astro-ph.SR|The Astrophysical...|10.1088/0004-637X...| 1207.2790|                null|http://arxiv.org/...|     null|   Markus Aschwanden|First 3D Reconstr...| 2015-06-05|[{Wed, 11 Jul 201...|[the, three-dimen...|[three-dimensiona...|(9964,[20,106,283...| 1207.2790|[2.76962644420564...|\n",
            "|  Despite being a...|J. A. Sherman, N....|[[Sherman, J. A.,...|physics.atom-ph p...|5 pages, 3 figure...|10.1103/PhysRevLe...| 1112.2766|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|        Jeff Sherman|High accuracy mea...| 2012-04-18|[{Tue, 13 Dec 201...|[despite, being, ...|[despite, canonic...|(9964,[93,411,351...| 1112.2766|[0.00317488005384...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator.setModelType(\"ARTM\")\n",
        "model = Pipeline(stages=[tokenizerARTM , estimator])\n",
        "res = model.fit(sentenceDataFrame).transform(sentenceDataFrame)\n",
        "res.show()"
      ],
      "metadata": {
        "id": "MVyB61IqI8Te",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017ff437-df5c-4096-c0bf-58b4db50e733"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the ARTM model is not pretrained, training on the transferred dataset\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "|            abstract|             authors|      authors_parsed|          categories|            comments|                 doi|        id|         journal-ref|             license|report-no|           submitter|               title|update_date|            versions|               words|              tokens|             vectors|        id|             vectors|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "|  The peak amplit...|      Sujan Sengupta|[[Sengupta, Sujan...|            astro-ph|16 pages includin...|      10.1086/591733| 0807.1794|                null|http://arxiv.org/...|     null|      Sujan Sengupta|Cloudy Atmosphere...| 2009-11-13|[{Fri, 11 Jul 200...|[the, peak, ampli...|[peak, amplitude,...|(9964,[431,1120],...| 0807.1794|[0.0, 0.162393152...|\n",
            "|  The antiferroma...|   Carlos P. Herrero|[[Herrero, Carlos...|     cond-mat.dis-nn|  7 pages, 6 figures|10.1140/epjb/e200...| 0908.3560|Eur. Phys. J. B 7...|http://arxiv.org/...|     null|   Carlos P. Herrero|Antiferromagnetic...| 2009-08-26|[{Tue, 25 Aug 200...|[the, antiferroma...|[antiferromagneti...|(9964,[70,126,342...| 0908.3560|[0.0, 0.0, 0.0, 0...|\n",
            "|  Models and meth...|Benjamin Collyer,...|[[Collyer, Benjam...|     physics.comp-ph|                null|10.1016/j.jcp.201...|1509.01015|                null|http://arxiv.org/...|     null|         Ben Collyer|Importance Sampli...| 2016-09-21|[{Thu, 3 Sep 2015...|[models, and, met...|[models, methods,...|(9964,[7,196,347,...|1509.01015|[0.0, 0.0, 0.2026...|\n",
            "|  An analytical m...|Mikhail B. Babenk...|[[Babenkov, Mikha...|cond-mat.stat-mec...|                null|                null|1802.02037|                null|http://arxiv.org/...|     null|    Mikhail Babenkov|Unsteady heat con...| 2018-02-07|[{Fri, 22 Dec 201...|[analytical, mode...|[analytical, freq...|   (9964,[49],[3.0])|1802.02037|[0.0, 0.0, 0.0, 0...|\n",
            "|  Recently, compr...|Sankalp Pawar, Se...|[[Pawar, Sankalp,...|             eess.SP|                null|                null|1811.01554|                null|http://arxiv.org/...|     null|    Sebastian Semper|Combining Matrix ...| 2018-11-06|[{Mon, 5 Nov 2018...|[recently, compre...|[recently, compre...|(9964,[1194,1944,...|1811.01554|[0.06666667014360...|\n",
            "|  We show that th...|Todd A. Thompson ...|[[Thompson, Todd ...|         astro-ph.GA|  9 pages, 5 figures|10.1093/mnras/stv...| 1411.1769|MNRAS 455, 334-34...|http://arxiv.org/...|     null|    Todd A. Thompson|Sub-Eddington Sta...| 2015-12-16|[{Thu, 6 Nov 2014...|[show, that, the,...|[turbulent, gas, ...|(9964,[15,63,101,...| 1411.1769|[0.0, 0.0, 0.0, 0...|\n",
            "|  From some works...|Georges Gras, Rol...|[[Gras, Georges, ...|             math.NT|This second versi...|                null| 1103.4692|                null|http://arxiv.org/...|     null|        Georges Gras|Some works of Fur...| 2011-04-14|[{Thu, 24 Mar 201...|[from, some, work...|[works, furtw, an...|(9964,[257,4125,4...| 1103.4692|[0.0, 0.0, 0.0, 0...|\n",
            "|  The stability o...|        Ahmad Borzou| [[Borzou, Ahmad, ]]|astro-ph.CO astro...|15 pages, 14 figu...|10.1140/epjc/s100...|2003.04532|Eur. Phys. J. C 8...|http://arxiv.org/...|     null|        Ahmad Borzou|On the Stability ...| 2020-11-24|[{Tue, 10 Mar 202...|[the, stability, ...|[stability, isoth...|(9964,[15,40,87,2...|2003.04532|[0.5, 0.0, 0.0, 0...|\n",
            "|  In this paper w...| Riccardo Cristoferi|[[Cristoferi, Ric...|             math.OC|23 pages, 14 figures|                null|1612.05508|                null|http://arxiv.org/...|     null| Riccardo Cristoferi|Exact solutions f...| 2017-09-12|[{Fri, 16 Dec 201...|[this, paper, pro...|[method, determin...|        (9964,[],[])|1612.05508|[0.06666667014360...|\n",
            "|  Let $w$ be a se...|Gordon Blower and...|[[Blower, Gordon,...|     math.FA math.CA|            30 pages|                null|1901.05788|                null|http://arxiv.org/...|     null|       Gordon Blower|On determinant ex...| 2019-02-07|[{Thu, 17 Jan 201...|[let, semiclassic...|[semiclassical, w...|(9964,[126,631,10...|1901.05788|[0.22709162533283...|\n",
            "|  We present an o...|Yongxin Chen, Try...|[[Chen, Yongxin, ...|       math.PR cs.SY|14 pages, 10 figures|                null|1710.07876|                null|http://arxiv.org/...|     null|        Yongxin Chen|Optimal transport...| 2018-02-01|[{Sun, 22 Oct 201...|[present, optimal...|[optimal, mass, t...|    (9964,[5],[3.0])|1710.07876|[0.0, 0.0, 1.0, 0...|\n",
            "|  Hysteresis oper...|Christian Kuehn a...|[[Kuehn, Christia...|math.DS math.CA n...|36 pages, 9 figur...|  10.1137/17M1110584|1701.00229|SIAM Journal on A...|http://arxiv.org/...|     null|     Christian Kuehn|Generalized Play ...| 2018-12-24|[{Sun, 1 Jan 2017...|[hysteresis, oper...|[hysteresis, oper...|(9964,[10,78,256,...|1701.00229|[0.11752576380968...|\n",
            "|  Predicate encry...|         Kwangsu Lee|  [[Lee, Kwangsu, ]]|               cs.CR|PhD Thesis, Korea...|                null|1702.07456|                null|http://arxiv.org/...|     null|         Kwangsu Lee|Efficient Hidden ...| 2017-02-27|[{Fri, 24 Feb 201...|[predicate, encry...|[predicate, encry...|(9964,[0,2,14,184...|1702.07456|[0.0, 0.0, 0.0, 0...|\n",
            "|  In recent work ...|J.I.A. Li, A.M. Z...|[[Li, J. I. A., ]...|   cond-mat.supr-con|4 pages and 3 fig...|10.1103/PhysRevLe...| 1401.5153|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|            J.I.A Li|Stability of supe...| 2014-03-19|[{Tue, 21 Jan 201...|[recent, work, wa...|[recent, shown, a...| (9964,[1577],[3.0])| 1401.5153|[0.0, 0.0, 0.5, 0...|\n",
            "|  Given a commuta...|         Liran Shaul|  [[Shaul, Liran, ]]|     math.AC math.AG|10 pages, final v...|10.1016/j.jpaa.20...|2002.05055|Journal of Pure a...|http://arxiv.org/...|     null|         Liran Shaul|Open loci results...| 2021-10-25|[{Wed, 12 Feb 202...|[given, commutati...|[given, commutati...|(9964,[316,3624,4...|2002.05055|[0.0, 0.0, 0.3257...|\n",
            "|  Related to a se...|Frederic Bernicot...|[[Bernicot, Frede...|             math.CA|            20 pages|                null| 1212.2349|                null|http://arxiv.org/...|     null|   Frederic Bernicot|Pseudodifferentia...| 2012-12-12|[{Tue, 11 Dec 201...|[related, semigro...|[related, semigro...|  (9964,[256],[3.0])| 1212.2349|[0.0, 0.0, 0.0, 0...|\n",
            "|  In an uncoordin...|Alphan Sahin, Erd...|[[Sahin, Alphan, ...|       cs.IT math.IT|Submitted to IEEE...|10.1109/TCOMM.201...| 1312.3662|                null|http://arxiv.org/...|     null|Alphan Sahin Alph...|Partially Overlap...| 2016-11-17|[{Thu, 12 Dec 201...|[uncoordinated, n...|[uncoordinated, n...|  (9964,[985],[4.0])| 1312.3662|[0.06666667014360...|\n",
            "|  This is era of ...|Rafiullah Khan an...|[[Khan, Rafiullah...|               cs.NI|  8 Pages, 4 figures|10.5121/cseij.201...| 1305.2708|                null|http://creativeco...|     null|      Rafiullah Khan|Conceptual Framew...| 2013-05-14|[{Mon, 13 May 201...|[this, era, infor...|[era, information...|(9964,[29,903,109...| 1305.2708|[0.0, 0.0, 0.0, 0...|\n",
            "|  The three-dimen...|Markus J. Aschwan...|[[Aschwanden, Mar...|         astro-ph.SR|The Astrophysical...|10.1088/0004-637X...| 1207.2790|                null|http://arxiv.org/...|     null|   Markus Aschwanden|First 3D Reconstr...| 2015-06-05|[{Wed, 11 Jul 201...|[the, three-dimen...|[three-dimensiona...|(9964,[20,106,283...| 1207.2790|[0.0, 0.072146840...|\n",
            "|  Despite being a...|J. A. Sherman, N....|[[Sherman, J. A.,...|physics.atom-ph p...|5 pages, 3 figure...|10.1103/PhysRevLe...| 1112.2766|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|        Jeff Sherman|High accuracy mea...| 2012-04-18|[{Tue, 13 Dec 201...|[despite, being, ...|[despite, canonic...|(9964,[93,411,351...| 1112.2766|[0.0, 0.0, 0.0, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.getStages()[1].getModelEstimator().saveModel(\"artm_model\")"
      ],
      "metadata": {
        "id": "shxD9wzk98cN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator2 = ProbabilityMatrixEstimator(inputCol=\"vectors\", \n",
        "                                        predictionCol=outputCol, \n",
        "                                        modelType=\"ARTM\",\n",
        "                                        prepared_string_tokens=string_tokens,\n",
        "                                        vocabulary=tokenizerARTM.getVocab()).fit(dataset) # fit only for getting probability model class, no need to specify correct dataFrame\n",
        "\n",
        "estimator2.loadModel(\"artm_model\").transform(dataset).show()"
      ],
      "metadata": {
        "id": "Dy9QYjSn-H7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ec3272-317a-44e7-d77a-0e9402deb647"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "|            abstract|             authors|      authors_parsed|          categories|            comments|                 doi|        id|         journal-ref|             license|report-no|           submitter|               title|update_date|            versions|               words|              tokens|             vectors|        id|             vectors|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "|  The peak amplit...|      Sujan Sengupta|[[Sengupta, Sujan...|            astro-ph|16 pages includin...|      10.1086/591733| 0807.1794|                null|http://arxiv.org/...|     null|      Sujan Sengupta|Cloudy Atmosphere...| 2009-11-13|[{Fri, 11 Jul 200...|[the, peak, ampli...|[peak, amplitude,...|(9964,[431,1120],...| 0807.1794|[0.0, 0.162393152...|\n",
            "|  The antiferroma...|   Carlos P. Herrero|[[Herrero, Carlos...|     cond-mat.dis-nn|  7 pages, 6 figures|10.1140/epjb/e200...| 0908.3560|Eur. Phys. J. B 7...|http://arxiv.org/...|     null|   Carlos P. Herrero|Antiferromagnetic...| 2009-08-26|[{Tue, 25 Aug 200...|[the, antiferroma...|[antiferromagneti...|(9964,[70,126,342...| 0908.3560|[0.0, 0.0, 0.0, 0...|\n",
            "|  Models and meth...|Benjamin Collyer,...|[[Collyer, Benjam...|     physics.comp-ph|                null|10.1016/j.jcp.201...|1509.01015|                null|http://arxiv.org/...|     null|         Ben Collyer|Importance Sampli...| 2016-09-21|[{Thu, 3 Sep 2015...|[models, and, met...|[models, methods,...|(9964,[7,196,347,...|1509.01015|[0.0, 0.0, 0.2026...|\n",
            "|  An analytical m...|Mikhail B. Babenk...|[[Babenkov, Mikha...|cond-mat.stat-mec...|                null|                null|1802.02037|                null|http://arxiv.org/...|     null|    Mikhail Babenkov|Unsteady heat con...| 2018-02-07|[{Fri, 22 Dec 201...|[analytical, mode...|[analytical, freq...|   (9964,[49],[3.0])|1802.02037|[0.0, 0.0, 0.0, 0...|\n",
            "|  Recently, compr...|Sankalp Pawar, Se...|[[Pawar, Sankalp,...|             eess.SP|                null|                null|1811.01554|                null|http://arxiv.org/...|     null|    Sebastian Semper|Combining Matrix ...| 2018-11-06|[{Mon, 5 Nov 2018...|[recently, compre...|[recently, compre...|(9964,[1194,1944,...|1811.01554|[0.06666667014360...|\n",
            "|  We show that th...|Todd A. Thompson ...|[[Thompson, Todd ...|         astro-ph.GA|  9 pages, 5 figures|10.1093/mnras/stv...| 1411.1769|MNRAS 455, 334-34...|http://arxiv.org/...|     null|    Todd A. Thompson|Sub-Eddington Sta...| 2015-12-16|[{Thu, 6 Nov 2014...|[show, that, the,...|[turbulent, gas, ...|(9964,[15,63,101,...| 1411.1769|[0.0, 0.0, 0.0, 0...|\n",
            "|  From some works...|Georges Gras, Rol...|[[Gras, Georges, ...|             math.NT|This second versi...|                null| 1103.4692|                null|http://arxiv.org/...|     null|        Georges Gras|Some works of Fur...| 2011-04-14|[{Thu, 24 Mar 201...|[from, some, work...|[works, furtw, an...|(9964,[257,4125,4...| 1103.4692|[0.0, 0.0, 0.0, 0...|\n",
            "|  The stability o...|        Ahmad Borzou| [[Borzou, Ahmad, ]]|astro-ph.CO astro...|15 pages, 14 figu...|10.1140/epjc/s100...|2003.04532|Eur. Phys. J. C 8...|http://arxiv.org/...|     null|        Ahmad Borzou|On the Stability ...| 2020-11-24|[{Tue, 10 Mar 202...|[the, stability, ...|[stability, isoth...|(9964,[15,40,87,2...|2003.04532|[0.5, 0.0, 0.0, 0...|\n",
            "|  In this paper w...| Riccardo Cristoferi|[[Cristoferi, Ric...|             math.OC|23 pages, 14 figures|                null|1612.05508|                null|http://arxiv.org/...|     null| Riccardo Cristoferi|Exact solutions f...| 2017-09-12|[{Fri, 16 Dec 201...|[this, paper, pro...|[method, determin...|        (9964,[],[])|1612.05508|[0.06666667014360...|\n",
            "|  Let $w$ be a se...|Gordon Blower and...|[[Blower, Gordon,...|     math.FA math.CA|            30 pages|                null|1901.05788|                null|http://arxiv.org/...|     null|       Gordon Blower|On determinant ex...| 2019-02-07|[{Thu, 17 Jan 201...|[let, semiclassic...|[semiclassical, w...|(9964,[126,631,10...|1901.05788|[0.22709162533283...|\n",
            "|  We present an o...|Yongxin Chen, Try...|[[Chen, Yongxin, ...|       math.PR cs.SY|14 pages, 10 figures|                null|1710.07876|                null|http://arxiv.org/...|     null|        Yongxin Chen|Optimal transport...| 2018-02-01|[{Sun, 22 Oct 201...|[present, optimal...|[optimal, mass, t...|    (9964,[5],[3.0])|1710.07876|[0.0, 0.0, 1.0, 0...|\n",
            "|  Hysteresis oper...|Christian Kuehn a...|[[Kuehn, Christia...|math.DS math.CA n...|36 pages, 9 figur...|  10.1137/17M1110584|1701.00229|SIAM Journal on A...|http://arxiv.org/...|     null|     Christian Kuehn|Generalized Play ...| 2018-12-24|[{Sun, 1 Jan 2017...|[hysteresis, oper...|[hysteresis, oper...|(9964,[10,78,256,...|1701.00229|[0.11752576380968...|\n",
            "|  Predicate encry...|         Kwangsu Lee|  [[Lee, Kwangsu, ]]|               cs.CR|PhD Thesis, Korea...|                null|1702.07456|                null|http://arxiv.org/...|     null|         Kwangsu Lee|Efficient Hidden ...| 2017-02-27|[{Fri, 24 Feb 201...|[predicate, encry...|[predicate, encry...|(9964,[0,2,14,184...|1702.07456|[0.0, 0.0, 0.0, 0...|\n",
            "|  In recent work ...|J.I.A. Li, A.M. Z...|[[Li, J. I. A., ]...|   cond-mat.supr-con|4 pages and 3 fig...|10.1103/PhysRevLe...| 1401.5153|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|            J.I.A Li|Stability of supe...| 2014-03-19|[{Tue, 21 Jan 201...|[recent, work, wa...|[recent, shown, a...| (9964,[1577],[3.0])| 1401.5153|[0.0, 0.0, 0.5, 0...|\n",
            "|  Given a commuta...|         Liran Shaul|  [[Shaul, Liran, ]]|     math.AC math.AG|10 pages, final v...|10.1016/j.jpaa.20...|2002.05055|Journal of Pure a...|http://arxiv.org/...|     null|         Liran Shaul|Open loci results...| 2021-10-25|[{Wed, 12 Feb 202...|[given, commutati...|[given, commutati...|(9964,[316,3624,4...|2002.05055|[0.0, 0.0, 0.3257...|\n",
            "|  Related to a se...|Frederic Bernicot...|[[Bernicot, Frede...|             math.CA|            20 pages|                null| 1212.2349|                null|http://arxiv.org/...|     null|   Frederic Bernicot|Pseudodifferentia...| 2012-12-12|[{Tue, 11 Dec 201...|[related, semigro...|[related, semigro...|  (9964,[256],[3.0])| 1212.2349|[0.0, 0.0, 0.0, 0...|\n",
            "|  In an uncoordin...|Alphan Sahin, Erd...|[[Sahin, Alphan, ...|       cs.IT math.IT|Submitted to IEEE...|10.1109/TCOMM.201...| 1312.3662|                null|http://arxiv.org/...|     null|Alphan Sahin Alph...|Partially Overlap...| 2016-11-17|[{Thu, 12 Dec 201...|[uncoordinated, n...|[uncoordinated, n...|  (9964,[985],[4.0])| 1312.3662|[0.06666667014360...|\n",
            "|  This is era of ...|Rafiullah Khan an...|[[Khan, Rafiullah...|               cs.NI|  8 Pages, 4 figures|10.5121/cseij.201...| 1305.2708|                null|http://creativeco...|     null|      Rafiullah Khan|Conceptual Framew...| 2013-05-14|[{Mon, 13 May 201...|[this, era, infor...|[era, information...|(9964,[29,903,109...| 1305.2708|[0.0, 0.0, 0.0, 0...|\n",
            "|  The three-dimen...|Markus J. Aschwan...|[[Aschwanden, Mar...|         astro-ph.SR|The Astrophysical...|10.1088/0004-637X...| 1207.2790|                null|http://arxiv.org/...|     null|   Markus Aschwanden|First 3D Reconstr...| 2015-06-05|[{Wed, 11 Jul 201...|[the, three-dimen...|[three-dimensiona...|(9964,[20,106,283...| 1207.2790|[0.0, 0.072146840...|\n",
            "|  Despite being a...|J. A. Sherman, N....|[[Sherman, J. A.,...|physics.atom-ph p...|5 pages, 3 figure...|10.1103/PhysRevLe...| 1112.2766|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|        Jeff Sherman|High accuracy mea...| 2012-04-18|[{Tue, 13 Dec 201...|[despite, being, ...|[despite, canonic...|(9964,[93,411,351...| 1112.2766|[0.0, 0.0, 0.0, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator.setModelType(\"AST\")\n",
        "estimator.setInputCol(\"tokens\")\n",
        "model = Pipeline(stages=[tokenizerParGenM, estimator])\n",
        "res = model.fit(sentenceDataFrame).transform(sentenceDataFrame)\n",
        "res.show()"
      ],
      "metadata": {
        "id": "q6Xmp_CZFfrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45a6163-ea54-43cc-cfc0-276c64a01e56"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+\n",
            "|            abstract|             authors|      authors_parsed|          categories|            comments|                 doi|        id|         journal-ref|             license|report-no|           submitter|               title|update_date|            versions|              tokens| probability vectors|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+\n",
            "|  The peak amplit...|      Sujan Sengupta|[[Sengupta, Sujan...|            astro-ph|16 pages includin...|      10.1086/591733| 0807.1794|                null|http://arxiv.org/...|     null|      Sujan Sengupta|Cloudy Atmosphere...| 2009-11-13|[{Fri, 11 Jul 200...|[the, peak, ampli...|[0.12364640369737...|\n",
            "|  This is era of ...|Rafiullah Khan an...|[[Khan, Rafiullah...|               cs.NI|  8 Pages, 4 figures|10.5121/cseij.201...| 1305.2708|                null|http://creativeco...|     null|      Rafiullah Khan|Conceptual Framew...| 2013-05-14|[{Mon, 13 May 201...|[this, is, era, o...|[0.11567859032473...|\n",
            "|  The three-dimen...|Markus J. Aschwan...|[[Aschwanden, Mar...|         astro-ph.SR|The Astrophysical...|10.1088/0004-637X...| 1207.2790|                null|http://arxiv.org/...|     null|   Markus Aschwanden|First 3D Reconstr...| 2015-06-05|[{Wed, 11 Jul 201...|[the, three-dimen...|[0.10076380532832...|\n",
            "|  Hysteresis oper...|Christian Kuehn a...|[[Kuehn, Christia...|math.DS math.CA n...|36 pages, 9 figur...|  10.1137/17M1110584|1701.00229|SIAM Journal on A...|http://arxiv.org/...|     null|     Christian Kuehn|Generalized Play ...| 2018-12-24|[{Sun, 1 Jan 2017...|[hysteresis, oper...|[0.12433905804561...|\n",
            "|  An analytical m...|Mikhail B. Babenk...|[[Babenkov, Mikha...|cond-mat.stat-mec...|                null|                null|1802.02037|                null|http://arxiv.org/...|     null|    Mikhail Babenkov|Unsteady heat con...| 2018-02-07|[{Fri, 22 Dec 201...|[an, analytical, ...|[0.11867513212138...|\n",
            "|  From some works...|Georges Gras, Rol...|[[Gras, Georges, ...|             math.NT|This second versi...|                null| 1103.4692|                null|http://arxiv.org/...|     null|        Georges Gras|Some works of Fur...| 2011-04-14|[{Thu, 24 Mar 201...|[from, some, work...|[0.13708903830513...|\n",
            "|  The stability o...|        Ahmad Borzou| [[Borzou, Ahmad, ]]|astro-ph.CO astro...|15 pages, 14 figu...|10.1140/epjc/s100...|2003.04532|Eur. Phys. J. C 8...|http://arxiv.org/...|     null|        Ahmad Borzou|On the Stability ...| 2020-11-24|[{Tue, 10 Mar 202...|[the, stability, ...|[0.11572613646336...|\n",
            "|  Let $w$ be a se...|Gordon Blower and...|[[Blower, Gordon,...|     math.FA math.CA|            30 pages|                null|1901.05788|                null|http://arxiv.org/...|     null|       Gordon Blower|On determinant ex...| 2019-02-07|[{Thu, 17 Jan 201...|[let, w, be, a, s...|[0.15420176329249...|\n",
            "|  In an uncoordin...|Alphan Sahin, Erd...|[[Sahin, Alphan, ...|       cs.IT math.IT|Submitted to IEEE...|10.1109/TCOMM.201...| 1312.3662|                null|http://arxiv.org/...|     null|Alphan Sahin Alph...|Partially Overlap...| 2016-11-17|[{Thu, 12 Dec 201...|[in, an, uncoordi...|[0.21788246325425...|\n",
            "|  Recently, compr...|Sankalp Pawar, Se...|[[Pawar, Sankalp,...|             eess.SP|                null|                null|1811.01554|                null|http://arxiv.org/...|     null|    Sebastian Semper|Combining Matrix ...| 2018-11-06|[{Mon, 5 Nov 2018...|[recently,, compr...|[0.11529537945821...|\n",
            "|  Related to a se...|Frederic Bernicot...|[[Bernicot, Frede...|             math.CA|            20 pages|                null| 1212.2349|                null|http://arxiv.org/...|     null|   Frederic Bernicot|Pseudodifferentia...| 2012-12-12|[{Tue, 11 Dec 201...|[related, to, a, ...|[0.09237920136445...|\n",
            "|  Predicate encry...|         Kwangsu Lee|  [[Lee, Kwangsu, ]]|               cs.CR|PhD Thesis, Korea...|                null|1702.07456|                null|http://arxiv.org/...|     null|         Kwangsu Lee|Efficient Hidden ...| 2017-02-27|[{Fri, 24 Feb 201...|[predicate, encry...|[0.15415846359921...|\n",
            "|  We show that th...|Todd A. Thompson ...|[[Thompson, Todd ...|         astro-ph.GA|  9 pages, 5 figures|10.1093/mnras/stv...| 1411.1769|MNRAS 455, 334-34...|http://arxiv.org/...|     null|    Todd A. Thompson|Sub-Eddington Sta...| 2015-12-16|[{Thu, 6 Nov 2014...|[we, show, that, ...|[0.12396830411951...|\n",
            "|  Models and meth...|Benjamin Collyer,...|[[Collyer, Benjam...|     physics.comp-ph|                null|10.1016/j.jcp.201...|1509.01015|                null|http://arxiv.org/...|     null|         Ben Collyer|Importance Sampli...| 2016-09-21|[{Thu, 3 Sep 2015...|[models, and, met...|[0.14536478177111...|\n",
            "|  Despite being a...|J. A. Sherman, N....|[[Sherman, J. A.,...|physics.atom-ph p...|5 pages, 3 figure...|10.1103/PhysRevLe...| 1112.2766|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|        Jeff Sherman|High accuracy mea...| 2012-04-18|[{Tue, 13 Dec 201...|[despite, being, ...|[0.10690504846164...|\n",
            "|  Given a commuta...|         Liran Shaul|  [[Shaul, Liran, ]]|     math.AC math.AG|10 pages, final v...|10.1016/j.jpaa.20...|2002.05055|Journal of Pure a...|http://arxiv.org/...|     null|         Liran Shaul|Open loci results...| 2021-10-25|[{Wed, 12 Feb 202...|[given, a, commut...|[0.11779800189097...|\n",
            "|  In recent work ...|J.I.A. Li, A.M. Z...|[[Li, J. I. A., ]...|   cond-mat.supr-con|4 pages and 3 fig...|10.1103/PhysRevLe...| 1401.5153|Phys. Rev. Lett. ...|http://arxiv.org/...|     null|            J.I.A Li|Stability of supe...| 2014-03-19|[{Tue, 21 Jan 201...|[in, recent, work...|[0.08032206048176...|\n",
            "|  We present an o...|Yongxin Chen, Try...|[[Chen, Yongxin, ...|       math.PR cs.SY|14 pages, 10 figures|                null|1710.07876|                null|http://arxiv.org/...|     null|        Yongxin Chen|Optimal transport...| 2018-02-01|[{Sun, 22 Oct 201...|[we, present, an,...|[0.13714004504321...|\n",
            "|  The antiferroma...|   Carlos P. Herrero|[[Herrero, Carlos...|     cond-mat.dis-nn|  7 pages, 6 figures|10.1140/epjb/e200...| 0908.3560|Eur. Phys. J. B 7...|http://arxiv.org/...|     null|   Carlos P. Herrero|Antiferromagnetic...| 2009-08-26|[{Tue, 25 Aug 200...|[the, antiferroma...|[0.10411285100781...|\n",
            "|  In this paper w...| Riccardo Cristoferi|[[Cristoferi, Ric...|             math.OC|23 pages, 14 figures|                null|1612.05508|                null|http://arxiv.org/...|     null| Riccardo Cristoferi|Exact solutions f...| 2017-09-12|[{Fri, 16 Dec 201...|[in, this, paper,...|[0.12554243845680...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+---------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import concat_ws, col\n",
        "\n",
        "res = model.fit(sentenceDataFrame).transform(sentenceDataFrame)\n",
        "\n",
        "df = res.select(\n",
        "    res.id,\n",
        "    concat_ws(\", \", col(outputCol).cast(\"array<string>\")).alias(outputCol)\n",
        ")\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "id": "LHr6ip6OQwQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b250e89b-e91e-43a9-a6bd-05b595fb0c28"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+\n",
            "|        id| probability vectors|\n",
            "+----------+--------------------+\n",
            "| 1209.6216|0.140598737678822...|\n",
            "|1709.04182|0.106697667561232...|\n",
            "|1806.05375|0.113710586324893...|\n",
            "| 1006.2878|0.102032642016370...|\n",
            "| 1412.8603|0.123145575745162...|\n",
            "|1812.07145|0.143490110227159...|\n",
            "| 0705.3351|0.096172604761553...|\n",
            "|1704.07768|0.099227267355376...|\n",
            "|1705.10430|0.124724408174861...|\n",
            "| 0908.3560|0.104112851007817...|\n",
            "|1605.06778|0.110553377237602...|\n",
            "| 0711.4286|0.133546557175506...|\n",
            "| 1403.1319|0.167583654299495...|\n",
            "| 1409.2746|0.124855467479590...|\n",
            "|1712.08272|0.143660288403234...|\n",
            "| 1103.6139|0.151706953044645...|\n",
            "|1907.02198|0.114791706850748...|\n",
            "| 0806.0924|0.155877523720106...|\n",
            "|1604.02815|0.115834280798670...|\n",
            "|1807.06428|0.145307900625078...|\n",
            "+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.repartition(1).write.mode(\"overwrite\").format(\"csv\").save(\"/content/Dataset/arxiv-relevance-matrix\")"
      ],
      "metadata": {
        "id": "E0g_vAPxxIkI"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}