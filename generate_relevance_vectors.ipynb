{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDK3tq4VCloZ"
      },
      "source": [
        "## Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WbmoXTSpAf8X"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import sys\n",
        "import os\n",
        "# installation of GOT (G eneralization O ver T axonomies) software package\n",
        "!mkdir gotlib\n",
        "if not os.listdir(\"gotlib\"):\n",
        "  !git clone https://github.com/dmitsf/GOT.git gotlib\n",
        "sys.path.append('gotlib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EegcgyJ9AiCH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python \n"
          ]
        }
      ],
      "source": [
        "#get taxonomy\n",
        "\n",
        "!python3 gotlib/got/taxonomies/taxonomy.py arxiv_category_taxonomy.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkwFLcTGCsYC"
      },
      "source": [
        "## Kaggle token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "5tCB73XGAouC",
        "outputId": "2619b4e5-4937-4b7e-f697-eff823016569"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "#files.upload()\n",
        "\n",
        "#!rm -r ~/.kaggle\n",
        "#!mkdir ~/.kaggle\n",
        "#!mv ./kaggle.json ~/.kaggle/\n",
        "#!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8luxZ5BCwXj"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e05ETiwAt--",
        "outputId": "d2e05ff0-83d5-4104-fc00-14375597be74"
      },
      "outputs": [],
      "source": [
        "# Downloading data\n",
        "#!pip install kaggle\n",
        "#!kaggle datasets download -d Cornell-University/arxiv\n",
        "\n",
        "#!mkdir Dataset\n",
        "#!cp arxiv.zip Dataset/arxiv.zip\n",
        "#!unzip -q Dataset/arxiv.zip -d Dataset\n",
        "#!rm Dataset/arxiv.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2OLkkPlfAyPX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dfs = pd.read_json('Dataset/arxiv-metadata-oai-snapshot.json', lines=True, chunksize = 1e3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vFxQM_7CA0U9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ESLGF_dCz1O"
      },
      "source": [
        "## Compute Relevance Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "84kC5Hd8ARZ9"
      },
      "outputs": [],
      "source": [
        "from got.asts.ast import EASA\n",
        "\n",
        "\n",
        "def clear_text(text, lowerize=True):\n",
        "\n",
        "    pat = re.compile(r'[^A-Za-z0-9 \\-\\n\\r.,;!?А-Яа-я]+')\n",
        "    cleared_text = re.sub(pat, ' ', text)\n",
        "\n",
        "    if lowerize:\n",
        "        cleared_text = cleared_text.lower()\n",
        "\n",
        "    tokens = cleared_text.split()\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def make_substrings(tokens, k=4):\n",
        "\n",
        "    for i in range(max(len(tokens) - k + 1, 1)):\n",
        "        yield ' '.join(tokens[i:i + k])\n",
        "\n",
        "\n",
        "def get_relevance_matrix(texts, strings):\n",
        "    matrix = np.empty((0, len(strings)), float) \n",
        "    prepared_text_tokens = [clear_text(t) for t in texts]\n",
        "\n",
        "    prepared_string_tokens = [clear_text(s) for s in strings]\n",
        "\n",
        "    prepared_strings = [' '.join(t) for t in prepared_string_tokens]\n",
        "\n",
        "    for text_tokens in prepared_text_tokens:\n",
        "        ast = EASA(list(make_substrings(text_tokens)))\n",
        "        row = np.array([ast.score(s) for s in prepared_strings])\n",
        "        matrix = np.append(matrix, [row], axis=0)\n",
        "\n",
        "    return matrix\n",
        "\n",
        "\n",
        "def save_matrix(matrix, lb, ub):\n",
        "    np.savetxt(\"relevance_matrix_{0}k-{1}k.txt\".format(lb, ub), matrix)\n",
        "\n",
        "\n",
        "\n",
        "with open(\"taxonomy_leaves.txt\") as f:\n",
        "    strings = [l.strip() for l in f.readlines()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "i = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "skip_first = 0\n",
        "work_until = 1000\n",
        "\n",
        "for data in dfs:\n",
        "    if i < skip_first:\n",
        "        i += 1\n",
        "        continue\n",
        "    print(data.index)\n",
        "    df = data[['abstract']]\n",
        "\n",
        "    sub_df = df.dropna(subset=['abstract'])\n",
        "    abstracts = sub_df['abstract'].to_list()\n",
        "    relevance_matrix = get_relevance_matrix(abstracts, strings)\n",
        "    save_matrix(relevance_matrix, i, (i + 1))\n",
        "    print(\"saved, shape: \", relevance_matrix.shape, \" it: \", i)\n",
        "    i += 1\n",
        "    if i == work_until:\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
